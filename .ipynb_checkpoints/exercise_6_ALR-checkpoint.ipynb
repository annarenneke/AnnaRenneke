{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** In most sessions you will be solving exercises posed in a Jupyter notebook that looks like this one. Because you are cloning a Github repository that only we can push to, you should **NEVER EDIT** any of the files you pull from Github. Instead, what you should do, is either make a new notebook and write your solutions in there, or **make a copy of this notebook and save it somewhere else** on your computer, not inside the `sds` folder that you cloned, so you can write your answers in there. If you edit the notebook you pulled from Github, those edits (possible your solutions to the exercises) may be overwritten and lost the next time you pull from Github. This is important, so don't hesitate to ask if it is unclear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Connector class for accessing the internet\n",
    "Even if logging is not important for the below exercises, get in the habit of using this class for connecting to the internet, to practice logging your activity. This will be expected in the final exam.\n",
    "\n",
    "You should run `pip install scraping_class` to install the module to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scraping_class\n",
    "logfile = 'log.csv'## name your log file.\n",
    "connector = scraping_class.Connector(logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import selenium\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T15:30:03.634114Z",
     "start_time": "2017-08-23T15:30:03.629294Z"
    }
   },
   "source": [
    "# Exercise Set 6: Introduction to Web Scraping\n",
    "\n",
    "In this Exercise Set we shall practice our webscraping skills utiilizing only basic python.  \n",
    "We shall cover variations between static and dynamic pages and build. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Section 6.1: Scraping Jobnet.dk\n",
    "\n",
    "This exercise you get to practice locating the request that the JavaScript sends to get the job data that it builds the joblistings from. You should use the **>Network Monitor<** tool in your browser.\n",
    "\n",
    "Furthermore you practice spotting how the pagination is done, without clicking on the next page button, but instead changing a small parameter in the URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.1:** Hit the joblisting webpage here: https://job.jobnet.dk/CV and locate the request that gets the joblisting data using the the **>Network Monitor<**. *(Hint: Filter by XHR files)  \n",
    "\n",
    "> **Ex. 6.1.2.:** Use the `request` module to collect the first 20 results and unpack the relevant `json` data into a `pandas` DataFrame.\n",
    "\n",
    "> **Ex. 6.1.3.:** Store the 'TotalResultCount' value for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13814"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE\n",
    "import requests\n",
    "import pandas as pd\n",
    "#laver link til data\n",
    "resp = requests.get('https://job.jobnet.dk/CV/FindWork/Search')\n",
    "#definerer med json\n",
    "TotalResultCount = resp.json()['JobPositionPostings']\n",
    "#loader data vha. pandas\n",
    "TotalResultCount2 = pd.DataFrame(TotalResultCount)\n",
    "TotalResultCount2\n",
    "#Vi gemmer antal jobopslag under variablen gem\n",
    "gem = resp.json()['TotalResultCount']\n",
    "#print\n",
    "gem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.4:** This exercise is about paging the results. We need to understand the websites pagination scheme. \n",
    "\n",
    "> Now scroll down the webpage and press the next page button. See how the parameters of the url changes as you turn the pages.\n",
    "\n",
    "> **Ex. 6.1.5:** Design a`for` loop using the `range` function that changes this paging parameter in the URL. Use the TotalResultCount parameter from before to define the limits of the range function. Store these urls in a container. \n",
    "\n",
    ">**extra** Change the SortValue parameter from BestMatch to CreationDate, to make the sorting amendable to updating results daily.\n",
    "\n",
    "*(HINT: See that the parameter is an offset and that this relates to the number of results pr. call made.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://job.jobnet.dk/CV/FindWork/Search?SortValue=CreationDate&Offset=13820'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE\n",
    "q = 'https://job.jobnet.dk/CV/FindWork/Search?SortValue=CreationDate&Offset=%d'\n",
    "links = []\n",
    "for offset in range(0,gem+20,20):\n",
    "    url = q%offset\n",
    "    links.append(url)\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex.6.1.6:** Pick 20 random links using the `random.sample()` function and collect them using the `Connector` class. Also use the `time.sleep()` function to limit the rate of your calls. Make sure to save the links already collected in a `set()` container to avoid having to reload links already collected. ***extra***: monitor the time left to completing the loop by using `tqdm.tqdm()` function.\n",
    "\n",
    "> **Ex.6.1.7:** Load all the results into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:28<00:00,  1.43s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AutomatchType</th>\n",
       "      <th>Abroad</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Title</th>\n",
       "      <th>JobHeadline</th>\n",
       "      <th>Presentation</th>\n",
       "      <th>HiringOrgName</th>\n",
       "      <th>WorkPlaceAddress</th>\n",
       "      <th>WorkPlacePostalCode</th>\n",
       "      <th>WorkPlaceCity</th>\n",
       "      <th>...</th>\n",
       "      <th>HiringOrgCVR</th>\n",
       "      <th>UserLoggedIn</th>\n",
       "      <th>AnonymousEmployer</th>\n",
       "      <th>ShareUrl</th>\n",
       "      <th>DetailsUrl</th>\n",
       "      <th>JobLogUrl</th>\n",
       "      <th>HasLocationValues</th>\n",
       "      <th>ID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SSA i dagvagt søges til Møllebo Plejehjem</td>\n",
       "      <td>SSA i dagvagt søges til Møllebo Plejehjem</td>\n",
       "      <td>Social- og sundhedsassistent søges til fast ...</td>\n",
       "      <td>Køge Kommune</td>\n",
       "      <td>Nørre Boulevard 101-105</td>\n",
       "      <td>4600</td>\n",
       "      <td>Køge</td>\n",
       "      <td>...</td>\n",
       "      <td>29189374</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://job.jobnet.dk/CV/FindWork/DetailsSocia...</td>\n",
       "      <td>https://job.jobnet.dk/CV/FindWork/Details/5178489</td>\n",
       "      <td>https://job.jobnet.dk/CV/FindWork/Details/5178489</td>\n",
       "      <td>True</td>\n",
       "      <td>5178489</td>\n",
       "      <td>55.4660</td>\n",
       "      <td>12.1813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Industrirengørings assitenter søges til arbejd...</td>\n",
       "      <td>Industrirengørings assitenter søges til arbejd...</td>\n",
       "      <td>&lt;p&gt;For en af vores gode kunder i Sønderjylland...</td>\n",
       "      <td>Medarbejderne ApS</td>\n",
       "      <td></td>\n",
       "      <td>6700</td>\n",
       "      <td>Esbjerg</td>\n",
       "      <td>...</td>\n",
       "      <td>32647677</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://job.jobnet.dk/CV/FindWork/DetailsSocia...</td>\n",
       "      <td>https://job.jobnet.dk/CV/FindWork/Details/5189025</td>\n",
       "      <td>https://job.jobnet.dk/CV/FindWork/Details/5189025</td>\n",
       "      <td>True</td>\n",
       "      <td>5189025</td>\n",
       "      <td>55.4594</td>\n",
       "      <td>8.4617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Social- og sundhedshjælper til Nørremølle plej...</td>\n",
       "      <td>Social- og sundhedshjælper til Nørremølle plej...</td>\n",
       "      <td>&lt;p&gt;Center for ældre Nørremøllecenteret søger 2...</td>\n",
       "      <td>Bornholms Regionskommune</td>\n",
       "      <td>Ullasvej 23</td>\n",
       "      <td>3700</td>\n",
       "      <td>Rønne</td>\n",
       "      <td>...</td>\n",
       "      <td>26696348</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://job.jobnet.dk/CV/FindWork/DetailsSocia...</td>\n",
       "      <td>https://job.jobnet.dk/CV/FindWork/Details/5186876</td>\n",
       "      <td>https://job.jobnet.dk/CV/FindWork/Details/5186876</td>\n",
       "      <td>True</td>\n",
       "      <td>5186876</td>\n",
       "      <td>55.0925</td>\n",
       "      <td>14.7087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Anlægsgartner/Brolægger/Murer</td>\n",
       "      <td>Anlægsgartner/Brolægger/Murer</td>\n",
       "      <td>&lt;p&gt;Vi søger en anlægsgartner som kan lidt af h...</td>\n",
       "      <td>JH Entreprise &amp; Service</td>\n",
       "      <td>H C Elgårds Vej 7</td>\n",
       "      <td>8961</td>\n",
       "      <td>Allingåbro</td>\n",
       "      <td>...</td>\n",
       "      <td>39753065</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://job.jobnet.dk/CV/FindWork/DetailsSocia...</td>\n",
       "      <td>https://job.jobnet.dk/CV/FindWork/Details/5188845</td>\n",
       "      <td>https://job.jobnet.dk/CV/FindWork/Details/5188845</td>\n",
       "      <td>True</td>\n",
       "      <td>5188845</td>\n",
       "      <td>56.4810</td>\n",
       "      <td>10.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Social- og sundhedshjælper til Torstorp Pleje-...</td>\n",
       "      <td>Social- og sundhedshjælper til Torstorp Pleje-...</td>\n",
       "      <td>I plejeboligerne søger vi en engageret social-...</td>\n",
       "      <td>Høje-Taastrup Kommune</td>\n",
       "      <td>Morelhaven 122</td>\n",
       "      <td>2630</td>\n",
       "      <td>Taastrup</td>\n",
       "      <td>...</td>\n",
       "      <td>19501817</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://job.jobnet.dk/CV/FindWork/DetailsSocia...</td>\n",
       "      <td>https://job.jobnet.dk/CV/FindWork/Details/5188277</td>\n",
       "      <td>https://job.jobnet.dk/CV/FindWork/Details/5188277</td>\n",
       "      <td>True</td>\n",
       "      <td>5188277</td>\n",
       "      <td>55.6387</td>\n",
       "      <td>12.2685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AutomatchType  Abroad  Weight  \\\n",
       "373              0   False     1.0   \n",
       "251              0   False     1.0   \n",
       "104              0   False     1.0   \n",
       "243              0   False     1.0   \n",
       "158              0   False     1.0   \n",
       "\n",
       "                                                 Title  \\\n",
       "373          SSA i dagvagt søges til Møllebo Plejehjem   \n",
       "251  Industrirengørings assitenter søges til arbejd...   \n",
       "104  Social- og sundhedshjælper til Nørremølle plej...   \n",
       "243                      Anlægsgartner/Brolægger/Murer   \n",
       "158  Social- og sundhedshjælper til Torstorp Pleje-...   \n",
       "\n",
       "                                           JobHeadline  \\\n",
       "373          SSA i dagvagt søges til Møllebo Plejehjem   \n",
       "251  Industrirengørings assitenter søges til arbejd...   \n",
       "104  Social- og sundhedshjælper til Nørremølle plej...   \n",
       "243                      Anlægsgartner/Brolægger/Murer   \n",
       "158  Social- og sundhedshjælper til Torstorp Pleje-...   \n",
       "\n",
       "                                          Presentation  \\\n",
       "373    Social- og sundhedsassistent søges til fast ...   \n",
       "251  <p>For en af vores gode kunder i Sønderjylland...   \n",
       "104  <p>Center for ældre Nørremøllecenteret søger 2...   \n",
       "243  <p>Vi søger en anlægsgartner som kan lidt af h...   \n",
       "158  I plejeboligerne søger vi en engageret social-...   \n",
       "\n",
       "                HiringOrgName         WorkPlaceAddress WorkPlacePostalCode  \\\n",
       "373              Køge Kommune  Nørre Boulevard 101-105                4600   \n",
       "251         Medarbejderne ApS                                         6700   \n",
       "104  Bornholms Regionskommune              Ullasvej 23                3700   \n",
       "243   JH Entreprise & Service        H C Elgårds Vej 7                8961   \n",
       "158     Høje-Taastrup Kommune           Morelhaven 122                2630   \n",
       "\n",
       "    WorkPlaceCity  ...  HiringOrgCVR  UserLoggedIn  AnonymousEmployer  \\\n",
       "373          Køge  ...      29189374         False              False   \n",
       "251       Esbjerg  ...      32647677         False              False   \n",
       "104         Rønne  ...      26696348         False              False   \n",
       "243    Allingåbro  ...      39753065         False              False   \n",
       "158      Taastrup  ...      19501817         False              False   \n",
       "\n",
       "                                              ShareUrl  \\\n",
       "373  https://job.jobnet.dk/CV/FindWork/DetailsSocia...   \n",
       "251  https://job.jobnet.dk/CV/FindWork/DetailsSocia...   \n",
       "104  https://job.jobnet.dk/CV/FindWork/DetailsSocia...   \n",
       "243  https://job.jobnet.dk/CV/FindWork/DetailsSocia...   \n",
       "158  https://job.jobnet.dk/CV/FindWork/DetailsSocia...   \n",
       "\n",
       "                                            DetailsUrl  \\\n",
       "373  https://job.jobnet.dk/CV/FindWork/Details/5178489   \n",
       "251  https://job.jobnet.dk/CV/FindWork/Details/5189025   \n",
       "104  https://job.jobnet.dk/CV/FindWork/Details/5186876   \n",
       "243  https://job.jobnet.dk/CV/FindWork/Details/5188845   \n",
       "158  https://job.jobnet.dk/CV/FindWork/Details/5188277   \n",
       "\n",
       "                                             JobLogUrl HasLocationValues  \\\n",
       "373  https://job.jobnet.dk/CV/FindWork/Details/5178489              True   \n",
       "251  https://job.jobnet.dk/CV/FindWork/Details/5189025              True   \n",
       "104  https://job.jobnet.dk/CV/FindWork/Details/5186876              True   \n",
       "243  https://job.jobnet.dk/CV/FindWork/Details/5188845              True   \n",
       "158  https://job.jobnet.dk/CV/FindWork/Details/5188277              True   \n",
       "\n",
       "          ID  Latitude  Longitude  \n",
       "373  5178489   55.4660    12.1813  \n",
       "251  5189025   55.4594     8.4617  \n",
       "104  5186876   55.0925    14.7087  \n",
       "243  5188845   56.4810    10.4500  \n",
       "158  5188277   55.6387    12.2685  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE\n",
    "\n",
    "import random\n",
    "import time\n",
    "done = set()\n",
    "data = []\n",
    "import tqdm\n",
    "for url in tqdm.tqdm(random.sample(links,20)):\n",
    "    response,call_id = connector.get(url,'download_jobposting')\n",
    "    if response.ok:\n",
    "        d = response.json()\n",
    "    else:\n",
    "        print('error')\n",
    "    data += d['JobPositionPostings']\n",
    "    time.sleep(0.5)\n",
    "df = pd.DataFrame(data)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Section 6.2: Scraping Trustpilot.com\n",
    "Now for a slightly more elaborate, yet still simple scraping problem. Here we want to scrape trustpilot for user reviews. This data is very nice since it provides free labeled data (rating) to train a machine learning model to understand positive and negative sentiment. \n",
    "\n",
    "Here you will practice crawling a website collecting the links to each company review page, and finally locate another behind the scenes JavaScript request that gets the review data in a neat json format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.2.1:** Visit the https://www.trustpilot.com/ website and locate the categories page.\n",
    "From this page you find links to company listings.\n",
    "\n",
    "> **Ex. 6.2.2:**\n",
    "Get the category page using the `requests` module and extract each link to a specific category page from the HTML. This can be done using the basic python `.split()` string method. Make sure only links within the ***/categories/*** section are kept, checking each string using the ```if 'pattern' in string``` condition. \n",
    "\n",
    "*(Hint: The links are relative. You need to add the domain name)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209 /categories/administration_services\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.trustpilot.com/categories/administration_services',\n",
       " 'https://www.trustpilot.com/categories/vocational_training',\n",
       " 'https://www.trustpilot.com/categories/middle_eastern_cuisine',\n",
       " 'https://www.trustpilot.com/categories/tattoos_piercings',\n",
       " 'https://www.trustpilot.com/categories/tobacco_store',\n",
       " 'https://www.trustpilot.com/categories/insurance',\n",
       " 'https://www.trustpilot.com/categories/adult_entertainment',\n",
       " 'https://www.trustpilot.com/categories/southeast_asian_cuisine',\n",
       " 'https://www.trustpilot.com/categories/dancing_gymnastics',\n",
       " 'https://www.trustpilot.com/categories/equipment_associations']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE\n",
    "url = 'https://www.trustpilot.com/categories'\n",
    "response,call_id = connector.get(url,'mapping_categories')\n",
    "if response.ok:\n",
    "    html = response.text\n",
    "else:\n",
    "    print('error')\n",
    "links = set()\n",
    "for link_loc in html.split('href=\"')[1:]:\n",
    "    link = link_loc.split('\"')[0]\n",
    "    if '/categories/' in link:\n",
    "        links.add(link)\n",
    "print(len(links),list(links)[0]) # link is relative\n",
    "links = ['https://www.trustpilot.com'+link for link in links]# add the domain to each link\n",
    "links[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.2.3:** Get one of the category section links. Write a function to extract the links to the company review page from the HTML.\n",
    "\n",
    "> **Ex. 6.2.4:** Figure out how the pagination is done, by following how the url changes when pressing the **next page**-button to obtain more company listings. Write a function that builds links to paging all the company listing results of each category. This includes parsing the number of subpages of each category and changing the correct parameter in the url.\n",
    "\n",
    "(Hint: Find the maximum number of result pages, right before the next page button and make a loop change the page parameter of the url.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "#CODE\n",
    "url = 'https://www.trustpilot.com/categories/art'\n",
    "response, _ = connector.get(url,'mapping')\n",
    "if response.ok:\n",
    "    html = response.text\n",
    "else:\n",
    "    print('error')\n",
    "def get_links(html):\n",
    "    links = set() # define container\n",
    "    for link_loc in html.split('href=\"')[1:]: # locate the start of a link\n",
    "        link = link_loc.split('\"')[0] # split at the end of the link\n",
    "        links.add(link) # if it is: add it to the set container\n",
    "    return links\n",
    "def get_company_links(html):\n",
    "    company_links = [link for link in get_links(html) if '/review/' in link] # check if the /review/ pattern is in the link\n",
    "    return company_links\n",
    "company_links = get_company_links(html)\n",
    "print(len(company_links))\n",
    "def get_all_category_pages(category_link):\n",
    "    response, _ = connector.get(category_link,'mapping_categories')\n",
    "    if response.ok:\n",
    "        html = response.text\n",
    "    else:\n",
    "        print('error')\n",
    "        return False\n",
    "    links = get_links(html)\n",
    "    # find the max_page.\n",
    "    page_links = [link for link in links if '?page=' in link] # check if the paging parameter is in the link\n",
    "    if len(page_links)==0: # no pages.\n",
    "        return [category_link]\n",
    "    n_pages = max([int(link.split('page=')[-1]) for link in page_links]) # extract the page value and take the max\n",
    "    paging_links = [category_link] # define container and store the original result page\n",
    "    q = category_link+'?page=%d' # define the varying parameter string.\n",
    "    for num in range(2,n_pages+1): # build the links.\n",
    "        paging_links.append(q%num)\n",
    "    return paging_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/review/makeshirtsnow.com',\n",
       " '/review/nametagcountry.com',\n",
       " '/review/diplomamakers.com',\n",
       " '/review/nicebadge.com',\n",
       " '/review/www.flickr.com',\n",
       " '/review/saatchiart.com',\n",
       " '/review/www.paleodirect.com',\n",
       " '/review/option-trades.com',\n",
       " '/review/elastihost.com',\n",
       " '/review/sparklesmakeitspecial.com',\n",
       " '/review/candlemaking.com',\n",
       " '/review/brandcrowd.com',\n",
       " '/review/monocoat.us',\n",
       " '/review/leafyquickwellness.com',\n",
       " '/review/paradiseawards.com',\n",
       " '/review/hosternow.com',\n",
       " '/review/www.brandedhairextensions.com',\n",
       " '/review/artmill.com',\n",
       " '/review/www.canvasgicleeprinting.com',\n",
       " '/review/supremepawtrait.com',\n",
       " '/review/www.stampanniething.com',\n",
       " '/review/matboardandmore.com',\n",
       " '/review/www.moo.com',\n",
       " '/review/tailorbrands.com',\n",
       " '/review/bestsuratsarees.com',\n",
       " '/review/zatista.com',\n",
       " '/review/modernpostcard.com',\n",
       " '/review/jasper52.com',\n",
       " '/review/hodgesbadge.com',\n",
       " '/review/www.icanvas.com',\n",
       " '/review/diyawards.com',\n",
       " '/review/mixbook.com',\n",
       " '/review/www.handmadepiece.com',\n",
       " '/review/stuff4crafts.com',\n",
       " '/review/www.crystalcentral.com',\n",
       " '/review/aliveadetox.com',\n",
       " '/review/www.twistedpride.com']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.2.5:** Loop through all categories and build the paging links using the above defined function.\n",
    "\n",
    "> **Ex. 6.2.6:** Randomly pick one of category listing links you have generated, and get the links to the companies listed using the other function defined. \n",
    "\n",
    "> **Ex. 6.2.7:** Visit one of these links and inspect the **>Network Monitor<** to locate the request that loads the review data. Use the requests module to retrieve this link and unpack the json results to a pandas DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We need to visit 2501 company listing pages to collect all company addresses\n"
     ]
    }
   ],
   "source": [
    "#CODE\n",
    "# ex. 6.2.5. Build the paging links\n",
    "\n",
    "# It may take som time to run\n",
    "# You'll find 1000+ links\n",
    "company_listings = []\n",
    "for link in links: \n",
    "    if 'support.trustpilot' in link:\n",
    "        continue\n",
    "    company_listings+=get_all_category_pages(link)\n",
    "print('We need to visit %d company listing pages to collect all company addresses'%len(company_listings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_links = get_company_links(random.choice(company_listings)) # use the above defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>@type</th>\n",
       "      <th>itemReviewed</th>\n",
       "      <th>author</th>\n",
       "      <th>datePublished</th>\n",
       "      <th>headline</th>\n",
       "      <th>reviewBody</th>\n",
       "      <th>reviewRating</th>\n",
       "      <th>publisher</th>\n",
       "      <th>inLanguage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>@type</th>\n",
       "      <td>Review</td>\n",
       "      <td>Thing</td>\n",
       "      <td>Person</td>\n",
       "      <td>2020-07-25T10:19:44Z</td>\n",
       "      <td>Perfect in every way.</td>\n",
       "      <td>Perfect in every way.</td>\n",
       "      <td>Rating</td>\n",
       "      <td>Organization</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>Review</td>\n",
       "      <td>Byapptonly</td>\n",
       "      <td>Adrienne</td>\n",
       "      <td>2020-07-25T10:19:44Z</td>\n",
       "      <td>Perfect in every way.</td>\n",
       "      <td>Perfect in every way.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trustpilot</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>Review</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.trustpilot.com/users/5f1c065af6abf...</td>\n",
       "      <td>2020-07-25T10:19:44Z</td>\n",
       "      <td>Perfect in every way.</td>\n",
       "      <td>Perfect in every way.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image</th>\n",
       "      <td>Review</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://user-images.trustpilot.com/5f1c065af6a...</td>\n",
       "      <td>2020-07-25T10:19:44Z</td>\n",
       "      <td>Perfect in every way.</td>\n",
       "      <td>Perfect in every way.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bestRating</th>\n",
       "      <td>Review</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-25T10:19:44Z</td>\n",
       "      <td>Perfect in every way.</td>\n",
       "      <td>Perfect in every way.</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             @type itemReviewed  \\\n",
       "@type       Review        Thing   \n",
       "name        Review   Byapptonly   \n",
       "url         Review          NaN   \n",
       "image       Review          NaN   \n",
       "bestRating  Review          NaN   \n",
       "\n",
       "                                                       author  \\\n",
       "@type                                                  Person   \n",
       "name                                                 Adrienne   \n",
       "url         https://www.trustpilot.com/users/5f1c065af6abf...   \n",
       "image       https://user-images.trustpilot.com/5f1c065af6a...   \n",
       "bestRating                                                NaN   \n",
       "\n",
       "                   datePublished               headline  \\\n",
       "@type       2020-07-25T10:19:44Z  Perfect in every way.   \n",
       "name        2020-07-25T10:19:44Z  Perfect in every way.   \n",
       "url         2020-07-25T10:19:44Z  Perfect in every way.   \n",
       "image       2020-07-25T10:19:44Z  Perfect in every way.   \n",
       "bestRating  2020-07-25T10:19:44Z  Perfect in every way.   \n",
       "\n",
       "                       reviewBody reviewRating     publisher inLanguage  \n",
       "@type       Perfect in every way.       Rating  Organization         en  \n",
       "name        Perfect in every way.          NaN    Trustpilot         en  \n",
       "url         Perfect in every way.          NaN           NaN         en  \n",
       "image       Perfect in every way.          NaN           NaN         en  \n",
       "bestRating  Perfect in every way.            5           NaN         en  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direct_link = 'https://www.trustpilot.com/reviews/5f1c07401a5a69075066f63d/jsonld'\n",
    "response, call_id = connector.get(direct_link, 'download_review')\n",
    "d = response.json() # parse json using the build-in function.\n",
    "df = pd.DataFrame(d)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "nav_menu": {
    "height": "87px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
